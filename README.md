# QLoRA
In this project, I fine tuned falcon-7B model on Google colab free-tier 16GB T4-GPU. This was pass because I used QLoRA fine tuning technique 
